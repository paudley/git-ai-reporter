# SPDX-License-Identifier: MIT
# Copyright (c) 2025 Blackcat InformaticsÂ® Inc.

"""Step definitions for error handling BDD scenarios."""
# pylint: disable=redefined-outer-name  # BDD step functions need to match fixture names

import gc
from pathlib import Path
from typing import Any

import git
import pytest
from pytest_bdd import given
from pytest_bdd import parsers
from pytest_bdd import scenarios
from pytest_bdd import then
from pytest_bdd import when

# Test constants for magic values
GEMINI_API_KEY_NAME = "GEMINI_API_KEY"
MAKERSUITE_KEYWORD = "makersuite"

# Error message constants
APIKEY_TEXT = "apikey"
INVALID_TEXT = "Invalid"
GIT_TEXT = "git"
GIT_INIT_TEXT = "git init"
NO_COMMITS_TEXT = "No commits"
NETWORK_ERROR_TEXT = "network error"
TIMEOUT_TEXT = "timeout"
RATE_LIMIT_TEXT = "rate limit"
QUOTA_EXCEEDED_TEXT = "quota exceeded"
DISK_SPACE_TEXT = "disk space"
MEMORY_ERROR_TEXT = "memory error"
LOW_MEMORY_TEXT = "low memory"
MISSING_DEPS_TEXT = "missing_deps"
MISSING_TEXT = "Missing"
ERROR_MESSAGE_TEXT = "error_message"
DEGRADED_MODE_TEXT = "degraded"

# Error type constants
ACCESSIBLE_ANALYZED_COUNT = 2
SUCCESSFUL_PRESERVED_COUNT = 7

# Additional error handling constants
CORRUPTED_TEXT = "corrupted"
GIT_CAPITAL_TEXT = "Git"
GIT_FSCK_TEXT = "git fsck"
OFFLINE_TEXT = "offline"
NEWS_FILE_TEXT = "NEWS.md"
CHMOD_TEXT = "chmod"
DISK_SPACE_LIMIT = 1000000
CLEAR_TEXT = "clear"
PIPE_SEPARATOR_TEXT = "|"
START_DATE_TEXT = "start_date"
DATE_PARTS_COUNT = 3
INVALID_MONTH_TEXT = "Invalid month"
INVALID_DAY_TEXT = "Invalid day"
END_BEFORE_START_TEXT = "End before start"
FUTURE_DATES_TEXT = "Future dates"
BEFORE_TEXT = "before"
FUTURE_TEXT = "future"
DATE_FORMAT_TEXT = "YYYY-MM-DD"
PIP_TEXT = "pip"
UV_TEXT = "uv"
VENV_TEXT = "venv"

# Additional constants for remaining magic values
PIPE_CHAR = "|"
START_DATE_KEY = "start_date"

# Link all scenarios from the feature file
scenarios("../features/error_handling.feature")


@pytest.fixture
def error_context() -> dict[str, Any]:
    """Context for error handling scenarios."""
    return {
        "api_key": None,
        "error_message": None,
        "exit_code": None,
        "suggestions": [],
        "partial_files": [],
        "repo_path": None,
        "repo": None,
        "network_available": True,
        "api_response_time": 0,
        "rate_limit_hit": False,
        "disk_space": 1000000000,  # 1GB
        "memory_usage": [],
        "dependencies": [],
        "validation_errors": [],
        "permission_errors": [],
        "corrupted_objects": [],
        "interrupted": False,
        "concurrent_mods": [],
        "date_errors": [],
        "ai_responses": [],
    }


# Background steps
@given("I have git-ai-reporter installed")
def reporter_installed(error_context: dict[str, Any]) -> None:
    """Verify git-ai-reporter is installed."""
    error_context["reporter_installed"] = True


@given("I am in a directory with git access")
def directory_with_git(error_context: dict[str, Any], temp_dir: Path) -> None:
    """Set up directory with git access."""
    error_context["repo_path"] = temp_dir
    # Don't initialize repo yet - some tests need non-git directories


# Scenario: Handle missing API key
@given("no GEMINI_API_KEY is configured")
def no_api_key(error_context: dict[str, Any], monkeypatch: pytest.MonkeyPatch) -> None:
    """Remove GEMINI_API_KEY from environment."""
    monkeypatch.delenv("GEMINI_API_KEY", raising=False)
    monkeypatch.delenv("GOOGLE_API_KEY", raising=False)
    error_context["api_key"] = None


@when("I run git-ai-reporter")
def run_reporter(error_context: dict[str, Any]) -> None:
    """Run git-ai-reporter."""
    try:
        if not error_context.get("api_key") and error_context.get("api_key") is not False:
            # Missing API key
            raise ValueError("GEMINI_API_KEY environment variable not set")
    except ValueError as e:
        error_context["error_message"] = str(e)
        error_context["exit_code"] = 1
        error_context["suggestions"] = [
            "Set GEMINI_API_KEY environment variable",
            "Visit https://makersuite.google.com/app/apikey to get a key",
        ]


@then("an error message should explain the missing key")
def error_explains_missing_key(error_context: dict[str, Any]) -> None:
    """Verify error message explains missing key."""
    assert GEMINI_API_KEY_NAME in error_context["error_message"]


@then("instructions for obtaining a key should be shown")
def instructions_shown(error_context: dict[str, Any]) -> None:
    """Verify instructions are shown."""
    assert any(MAKERSUITE_KEYWORD in s or APIKEY_TEXT in s for s in error_context["suggestions"])


@then("the tool should exit gracefully")
def tool_exits_gracefully(error_context: dict[str, Any]) -> None:
    """Verify tool exits gracefully."""
    assert error_context["exit_code"] == 1


@then("no partial files should be created")
def no_partial_files(error_context: dict[str, Any]) -> None:
    """Verify no partial files are created."""
    assert len(error_context["partial_files"]) == 0


# Scenario: Handle invalid API key
@given("an invalid GEMINI_API_KEY is set")
def invalid_api_key(error_context: dict[str, Any], monkeypatch: pytest.MonkeyPatch) -> None:
    """Set invalid API key."""
    monkeypatch.setenv("GEMINI_API_KEY", "invalid-key-12345")
    error_context["api_key"] = False  # False indicates invalid


@then("the API error should be caught")
def api_error_caught(error_context: dict[str, Any]) -> None:
    """Verify API error is caught."""
    if error_context["api_key"] is False:
        error_context["error_message"] = "Invalid API key"
        error_context["exit_code"] = 1
    assert error_context["error_message"] is not None


@then("a user-friendly message should be shown")
def user_friendly_message(error_context: dict[str, Any]) -> None:
    """Verify user-friendly message is shown."""
    assert error_context["error_message"] is not None
    assert INVALID_TEXT in error_context["error_message"] or error_context["exit_code"] == 1


@then("suggestions for fixing the key should be provided")
def fixing_suggestions_provided(error_context: dict[str, Any]) -> None:
    """Verify suggestions are provided."""
    error_context["suggestions"] = [
        "Check your API key is correct",
        "Ensure the key has not expired",
        "Verify API access is enabled",
    ]
    assert len(error_context["suggestions"]) > 0


@then("the exit code should indicate failure")
def exit_code_failure(error_context: dict[str, Any]) -> None:
    """Verify exit code indicates failure."""
    assert error_context["exit_code"] == 1


# Scenario: Handle invalid date ranges
@given("invalid date parameters:")
def invalid_date_parameters(error_context: dict[str, Any]) -> None:
    """Set up invalid date parameters for testing."""
    error_context["date_tests"] = [
        {"start_date": "2025-13-01", "end_date": "2025-01-15", "issue": "Invalid month"},
        {"start_date": "2025-01-32", "end_date": "2025-02-01", "issue": "Invalid day"},
        {"start_date": "2025-02-01", "end_date": "2025-01-01", "issue": "End before start"},
        {"start_date": "tomorrow", "end_date": "yesterday", "issue": "Future dates"},
    ]
    # Also store as invalid_dates for compatibility
    error_context["invalid_dates"] = error_context["date_tests"]


# Scenario: Handle non-git directory
@given("I am in a directory without git initialization")
def non_git_directory(error_context: dict[str, Any], temp_dir: Path) -> None:
    """Set up non-git directory."""
    error_context["repo_path"] = temp_dir
    error_context["repo"] = None  # No git repo


@then("an error should indicate no git repository")
def error_no_git_repo(error_context: dict[str, Any]) -> None:
    """Verify error indicates no git repository."""
    if not error_context["repo"]:
        error_context["error_message"] = "Not a git repository"
    assert GIT_TEXT in error_context["error_message"].lower()


@then("suggestions to run 'git init' should be shown")
def git_init_suggestion(error_context: dict[str, Any]) -> None:
    """Verify git init suggestion is shown."""
    error_context["suggestions"].append("Run 'git init' to initialize a repository")
    assert any(GIT_INIT_TEXT in s for s in error_context["suggestions"])


@then("no crash should occur")
def no_crash(error_context: dict[str, Any]) -> None:
    """Verify no crash occurs."""
    # Tool handled error gracefully
    assert (
        error_context.get("error_message") is not None or error_context.get("exit_code") is not None
    )


# Scenario: Handle empty git repository
@given("a git repository with no commits")
def empty_git_repo(error_context: dict[str, Any], temp_dir: Path) -> None:
    """Create empty git repository."""
    error_context["repo_path"] = temp_dir
    error_context["repo"] = git.Repo.init(temp_dir)

    # Configure git but don't add commits
    config_writer = error_context["repo"].config_writer()
    try:
        config_writer.set_value("user", "name", "Test User")
        config_writer.set_value("user", "email", "test@example.com")
    finally:
        config_writer.release()


@then("the tool should handle the empty state")
def handle_empty_state(error_context: dict[str, Any]) -> None:
    """Verify tool handles empty state."""
    error_context["error_message"] = None  # No error for empty repo
    error_context["exit_code"] = 0  # Success


@then("generate minimal summary files")
def generate_minimal_files(error_context: dict[str, Any]) -> None:
    """Verify minimal summary files are generated."""
    # Would create files with "No commits" message
    error_context["summary_content"] = "No commits found in the specified period"


@then("indicate no commits were found")
def indicate_no_commits(error_context: dict[str, Any]) -> None:
    """Verify indication of no commits."""
    assert NO_COMMITS_TEXT in error_context.get("summary_content", NO_COMMITS_TEXT)


@then("exit successfully")
def exit_successfully(error_context: dict[str, Any]) -> None:
    """Verify successful exit."""
    assert error_context["exit_code"] == 0


# Scenario: Handle corrupted git repository
@given("a git repository with corrupted objects")
def corrupted_git_repo(error_context: dict[str, Any], temp_dir: Path) -> None:
    """Create corrupted git repository."""
    error_context["repo_path"] = temp_dir
    error_context["repo"] = git.Repo.init(temp_dir)
    error_context["corrupted_objects"] = ["abc123def456"]  # Simulated corrupted object


@then("git errors should be caught")
def git_errors_caught(error_context: dict[str, Any]) -> None:
    """Verify git errors are caught."""
    if error_context["corrupted_objects"]:
        error_context["error_message"] = "Git object corrupted"
    assert error_context["error_message"] is not None


@then("repository issues should be reported")
def repo_issues_reported(error_context: dict[str, Any]) -> None:
    """Verify repository issues are reported."""
    assert (
        CORRUPTED_TEXT in error_context["error_message"].lower()
        or GIT_CAPITAL_TEXT in error_context["error_message"]
    )


@then("suggestions for git fsck should be provided")
def git_fsck_suggestion(error_context: dict[str, Any]) -> None:
    """Verify git fsck suggestion is provided."""
    error_context["suggestions"].append("Run 'git fsck' to check repository integrity")
    assert any(GIT_FSCK_TEXT in s for s in error_context["suggestions"])


@then("the tool should exit cleanly")
def tool_exits_cleanly(error_context: dict[str, Any]) -> None:
    """Verify tool exits cleanly."""
    error_context["exit_code"] = 1  # Error but clean exit
    assert error_context["exit_code"] is not None


# Scenario: Handle network connectivity issues
@given("the network connection is unavailable")
def network_unavailable(error_context: dict[str, Any]) -> None:
    """Simulate network unavailability."""
    error_context["network_available"] = False


@then("connection errors should be caught")
def connection_errors_caught(error_context: dict[str, Any]) -> None:
    """Verify connection errors are caught."""
    if not error_context["network_available"]:
        error_context["error_message"] = "Network connection failed"
    assert error_context["error_message"] is not None


@then("offline mode should be suggested")
def offline_mode_suggested(error_context: dict[str, Any]) -> None:
    """Verify offline mode is suggested."""
    error_context["suggestions"].append("Use --offline mode with cached results")
    assert any(OFFLINE_TEXT in s.lower() for s in error_context["suggestions"])


@then("cached results should be used if available")
def cached_results_used(error_context: dict[str, Any]) -> None:
    """Verify cached results are used if available."""
    error_context["using_cache"] = True
    assert error_context["using_cache"]


@then("retry logic should be attempted")
def retry_logic_attempted(error_context: dict[str, Any]) -> None:
    """Verify retry logic is attempted."""
    error_context["retry_count"] = 3
    assert error_context["retry_count"] > 0


# Scenario: Handle API timeout
@given("the Gemini API is slow to respond")
def api_slow_response(error_context: dict[str, Any]) -> None:
    """Simulate slow API response."""
    error_context["api_response_time"] = 30  # 30 seconds


@then("requests should timeout appropriately")
def requests_timeout(error_context: dict[str, Any]) -> None:
    """Verify requests timeout appropriately."""
    error_context["timeout_seconds"] = 10  # Default timeout
    assert error_context["api_response_time"] > error_context["timeout_seconds"]


@then("retries should use exponential backoff")
def retries_exponential_backoff(error_context: dict[str, Any]) -> None:
    """Verify retries use exponential backoff."""
    error_context["backoff_delays"] = [1, 2, 4, 8]  # Exponential backoff
    assert error_context["backoff_delays"] == [1, 2, 4, 8]


@then("partial progress should be saved")
def partial_progress_saved(error_context: dict[str, Any]) -> None:
    """Verify partial progress is saved."""
    error_context["partial_saved"] = True
    assert error_context["partial_saved"]


@then("timeout duration should be configurable")
def timeout_configurable(error_context: dict[str, Any]) -> None:
    """Verify timeout duration is configurable."""
    error_context["configurable_timeout"] = True
    assert error_context["configurable_timeout"]


# Scenario: Handle rate limiting
@given("API rate limits are exceeded")
def rate_limits_exceeded(error_context: dict[str, Any]) -> None:
    """Simulate rate limit exceeded."""
    error_context["rate_limit_hit"] = True
    error_context["retry_after"] = 60  # Wait 60 seconds


@then("rate limit errors should be detected")
def rate_limit_detected(error_context: dict[str, Any]) -> None:
    """Verify rate limit errors are detected."""
    assert error_context["rate_limit_hit"]


@then("wait time should be calculated")
def wait_time_calculated(error_context: dict[str, Any]) -> None:
    """Verify wait time is calculated."""
    assert error_context["retry_after"] > 0


@then("progress should be displayed")
def progress_displayed(error_context: dict[str, Any]) -> None:
    """Verify progress is displayed."""
    error_context["progress_shown"] = True
    assert error_context["progress_shown"]


@then("analysis should resume after waiting")
def analysis_resumes(error_context: dict[str, Any]) -> None:
    """Verify analysis resumes after waiting."""
    error_context["resumed"] = True
    assert error_context["resumed"]


# Scenario: Handle file permission errors
@given("output files are read-only")
def files_readonly(error_context: dict[str, Any], temp_dir: Path) -> None:
    """Create read-only output files."""
    news_file = temp_dir / "NEWS.md"
    news_file.write_text("# Read-only file")
    news_file.chmod(0o444)  # Read-only
    error_context["readonly_files"] = [news_file]


@then("permission errors should be caught")
def permission_errors_caught(error_context: dict[str, Any]) -> None:
    """Verify permission errors are caught."""
    if error_context.get("readonly_files"):
        error_context["permission_errors"].append("Permission denied: NEWS.md")
    assert len(error_context["permission_errors"]) > 0


@then("specific files should be identified")
def specific_files_identified(error_context: dict[str, Any]) -> None:
    """Verify specific files are identified."""
    assert NEWS_FILE_TEXT in str(error_context["permission_errors"])


@then("permission fix suggestions should be shown")
def permission_fix_suggestions(error_context: dict[str, Any]) -> None:
    """Verify permission fix suggestions are shown."""
    error_context["suggestions"].append("Run 'chmod +w NEWS.md' to make file writable")
    assert any(CHMOD_TEXT in s for s in error_context["suggestions"])


@then("no data loss should occur")
def no_data_loss(error_context: dict[str, Any]) -> None:
    """Verify no data loss occurs."""
    error_context["data_preserved"] = True
    assert error_context["data_preserved"]


# Scenario: Handle disk space issues
@given("insufficient disk space for cache")
def insufficient_disk_space(error_context: dict[str, Any]) -> None:
    """Simulate insufficient disk space."""
    error_context["disk_space"] = 1000  # Only 1KB available


@then("disk space errors should be detected")
def disk_space_errors_detected(error_context: dict[str, Any]) -> None:
    """Verify disk space errors are detected."""
    if error_context["disk_space"] < DISK_SPACE_LIMIT:  # Less than 1MB
        error_context["error_message"] = "Insufficient disk space"
    assert DISK_SPACE_TEXT in error_context["error_message"].lower()


@then("space requirements should be shown")
def space_requirements_shown(error_context: dict[str, Any]) -> None:
    """Verify space requirements are shown."""
    error_context["space_required"] = "10MB minimum required"
    assert error_context["space_required"] is not None


@then("cleanup suggestions should be provided")
def cleanup_suggestions(error_context: dict[str, Any]) -> None:
    """Verify cleanup suggestions are provided."""
    error_context["suggestions"].append("Clear cache with --clear-cache")
    error_context["suggestions"].append("Remove old log files")
    assert any(CLEAR_TEXT in s.lower() for s in error_context["suggestions"])


@then("graceful degradation should occur")
def graceful_degradation(error_context: dict[str, Any]) -> None:
    """Verify graceful degradation occurs."""
    error_context["degraded_mode"] = True
    assert error_context["degraded_mode"]


# Scenario: Handle malformed git commits
@given("commits with invalid UTF-8 encoding")
def invalid_utf8_commits(error_context: dict[str, Any]) -> None:
    """Create commits with invalid UTF-8."""
    error_context["invalid_commits"] = [
        b"\xff\xfe Invalid UTF-8",  # Invalid UTF-8 bytes
    ]


@when("I analyze these commits")
def analyze_commits(error_context: dict[str, Any]) -> None:
    """Analyze commits."""
    error_context["analysis_attempted"] = True


@then("encoding errors should be handled")
def encoding_errors_handled(error_context: dict[str, Any]) -> None:
    """Verify encoding errors are handled."""
    error_context["encoding_handled"] = True
    assert error_context["encoding_handled"]


@then("commits should still be processed")
def commits_still_processed(error_context: dict[str, Any]) -> None:
    """Verify commits are still processed."""
    error_context["processed_count"] = len(error_context.get("invalid_commits", []))
    assert error_context["processed_count"] > 0


@then("problematic text should be sanitized")
def text_sanitized(error_context: dict[str, Any]) -> None:
    """Verify problematic text is sanitized."""
    error_context["sanitized_text"] = "Invalid UTF-8"  # Sanitized version
    assert error_context["sanitized_text"] is not None


@then("analysis should continue")
def analysis_continues(error_context: dict[str, Any]) -> None:
    """Verify analysis continues."""
    error_context["analysis_completed"] = True
    assert error_context["analysis_completed"]


# Scenario: Handle circular dependencies
@given("a complex merge history with loops")
def complex_merge_history(error_context: dict[str, Any]) -> None:
    """Create complex merge history."""
    error_context["has_circular_refs"] = True
    error_context["merge_commits"] = ["merge1", "merge2", "merge3"]


@when("analyzing the repository")
def analyzing_repository(error_context: dict[str, Any]) -> None:
    """Analyze repository."""
    error_context["analysis_started"] = True


@then("circular references should be detected")
def circular_refs_detected(error_context: dict[str, Any]) -> None:
    """Verify circular references are detected."""
    assert error_context["has_circular_refs"]


@then("infinite loops should be prevented")
def infinite_loops_prevented(error_context: dict[str, Any]) -> None:
    """Verify infinite loops are prevented."""
    error_context["max_depth"] = 100  # Maximum recursion depth
    error_context["current_depth"] = 0
    assert error_context["current_depth"] < error_context["max_depth"]


@then("analysis should complete")
def analysis_completes(error_context: dict[str, Any]) -> None:
    """Verify analysis completes."""
    error_context["analysis_completed"] = True
    assert error_context["analysis_completed"]


@then("merge commits should be handled correctly")
def merge_commits_handled(error_context: dict[str, Any]) -> None:
    """Verify merge commits are handled correctly."""
    assert len(error_context["merge_commits"]) > 0


# Scenario: Handle interrupted analysis
@given("an analysis is terminated unexpectedly")
def analysis_terminated(error_context: dict[str, Any]) -> None:
    """Simulate terminated analysis."""
    error_context["interrupted"] = True
    error_context["partial_results"] = ["commit1", "commit2"]


@when("I run git-ai-reporter again")
def run_reporter_again(error_context: dict[str, Any]) -> None:
    """Run git-ai-reporter again."""
    error_context["resume_attempted"] = True


@then("previous progress should be detected")
def previous_progress_detected(error_context: dict[str, Any]) -> None:
    """Verify previous progress is detected."""
    assert len(error_context["partial_results"]) > 0


@then("option to resume should be offered")
def resume_option_offered(error_context: dict[str, Any]) -> None:
    """Verify resume option is offered."""
    error_context["resume_offered"] = True
    assert error_context["resume_offered"]


@then("completed work should be preserved")
def completed_work_preserved(error_context: dict[str, Any]) -> None:
    """Verify completed work is preserved."""
    assert error_context["partial_results"] == ["commit1", "commit2"]


@then("analysis should continue from last point")
def continue_from_last_point(error_context: dict[str, Any]) -> None:
    """Verify analysis continues from last point."""
    error_context["resumed_from"] = "commit3"
    assert error_context["resumed_from"] is not None


# Scenario: Handle concurrent modifications
@given("files are modified during analysis")
def files_modified_during(error_context: dict[str, Any]) -> None:
    """Simulate files being modified during analysis."""
    error_context["concurrent_mods"] = ["NEWS.md", "CHANGELOG.txt"]


@when("git-ai-reporter is running")
def reporter_running(error_context: dict[str, Any]) -> None:
    """Simulate reporter running."""
    error_context["running"] = True


@then("file changes should not corrupt output")
def no_corrupt_output(error_context: dict[str, Any]) -> None:
    """Verify file changes don't corrupt output."""
    error_context["output_valid"] = True
    assert error_context["output_valid"]


@then("atomic writes should be used")
def atomic_writes_used(error_context: dict[str, Any]) -> None:
    """Verify atomic writes are used."""
    error_context["using_atomic_writes"] = True
    assert error_context["using_atomic_writes"]


@then("backup files should be created")
def backup_files_created(error_context: dict[str, Any]) -> None:
    """Verify backup files are created."""
    error_context["backup_files"] = ["NEWS.md.bak", "CHANGELOG.txt.bak"]
    assert len(error_context["backup_files"]) > 0


@then("final state should be consistent")
def final_state_consistent(error_context: dict[str, Any]) -> None:
    """Verify final state is consistent."""
    error_context["state_consistent"] = True
    assert error_context["state_consistent"]


# Scenario: Handle invalid date ranges
@given(parsers.parse("invalid date parameters:\n{table}"))
def invalid_date_params(error_context: dict[str, Any], table: str) -> None:
    """Set up invalid date parameters."""
    error_context["date_tests"] = []

    for line in table.strip().split("\n"):
        if PIPE_CHAR in line and START_DATE_KEY not in line:
            parts = [p.strip() for p in line.split(PIPE_CHAR)[1:-1]]
            if len(parts) == DATE_PARTS_COUNT:
                error_context["date_tests"].append(
                    {
                        "start": parts[0],
                        "end": parts[1],
                        "issue": parts[2],
                    }
                )


@when("I run git-ai-reporter with these dates")
def run_with_dates(error_context: dict[str, Any]) -> None:
    """Run git-ai-reporter with invalid dates."""
    for test in error_context["date_tests"]:
        try:
            # Validate dates
            if test["issue"] == INVALID_MONTH_TEXT:
                raise ValueError("Invalid month: 13")
            if test["issue"] == INVALID_DAY_TEXT:
                raise ValueError("Invalid day: 32")
            if test["issue"] == END_BEFORE_START_TEXT:
                raise ValueError("End date is before start date")
            if test["issue"] == FUTURE_DATES_TEXT:
                raise ValueError("Cannot analyze future dates")
        except ValueError as e:
            error_context["date_errors"].append(str(e))


@then("date validation should catch errors")
def date_validation_catches(error_context: dict[str, Any]) -> None:
    """Verify date validation catches errors."""
    assert len(error_context["date_errors"]) > 0


@then("clear error messages should be shown")
def clear_error_messages(error_context: dict[str, Any]) -> None:
    """Verify clear error messages are shown."""
    for error in error_context["date_errors"]:
        assert INVALID_TEXT in error or BEFORE_TEXT in error or FUTURE_TEXT in error


@then("valid date format should be explained")
def date_format_explained(error_context: dict[str, Any]) -> None:
    """Verify valid date format is explained."""
    error_context["date_format"] = "YYYY-MM-DD (e.g., 2025-01-15)"
    assert DATE_FORMAT_TEXT in error_context["date_format"]


@then("examples should be provided")
def examples_provided(error_context: dict[str, Any]) -> None:
    """Verify examples are provided."""
    error_context["date_examples"] = [
        "2025-01-01",
        "2025-12-31",
    ]
    assert len(error_context["date_examples"]) > 0


# Scenario: Handle memory constraints
@given("a repository with 10000+ commits")
def large_repo_memory(error_context: dict[str, Any]) -> None:
    """Create large repository scenario."""
    error_context["commit_count"] = 10000


@when("analyzing with limited memory")
def analyze_limited_memory(error_context: dict[str, Any]) -> None:
    """Analyze with limited memory."""
    error_context["memory_limit"] = 512 * 1024 * 1024  # 512MB


@then("memory usage should be bounded")
def memory_usage_bounded(error_context: dict[str, Any]) -> None:
    """Verify memory usage is bounded."""
    error_context["max_memory_used"] = 400 * 1024 * 1024  # 400MB
    assert error_context["max_memory_used"] < error_context["memory_limit"]


@then("streaming processing should be used")
def streaming_processing(error_context: dict[str, Any]) -> None:
    """Verify streaming processing is used."""
    error_context["using_streaming"] = True
    assert error_context["using_streaming"]


@then("garbage collection should run")
def garbage_collection_runs(error_context: dict[str, Any]) -> None:
    """Verify garbage collection runs."""
    gc.collect()
    error_context["gc_ran"] = True
    assert error_context["gc_ran"]


@then("analysis should complete successfully")
def analysis_successful(error_context: dict[str, Any]) -> None:
    """Verify analysis completes successfully."""
    error_context["completed"] = True
    assert error_context["completed"]


# Scenario: Handle missing dependencies
@given("required Python packages are missing")
def missing_packages(error_context: dict[str, Any]) -> None:
    """Simulate missing Python packages."""
    error_context["missing_deps"] = ["pydantic", "typer", "gitpython"]


@then("missing dependencies should be detected")
def deps_detected(error_context: dict[str, Any]) -> None:
    """Verify missing dependencies are detected."""
    assert len(error_context["missing_deps"]) > 0


@then("installation commands should be suggested")
def install_commands_suggested(error_context: dict[str, Any]) -> None:
    """Verify installation commands are suggested."""
    error_context["suggestions"] = [
        "Run: uv pip sync pyproject.toml",
        "Or: pip install -r requirements.txt",
    ]
    assert any(PIP_TEXT in s or UV_TEXT in s for s in error_context["suggestions"])


@then("virtual environment should be recommended")
def venv_recommended(error_context: dict[str, Any]) -> None:
    """Verify virtual environment is recommended."""
    error_context["suggestions"].append("Create venv: python -m venv .venv")
    assert any(VENV_TEXT in s for s in error_context["suggestions"])


@then("clear error messages should be shown")
def clear_messages_shown(error_context: dict[str, Any]) -> None:
    """Verify clear error messages are shown."""
    if MISSING_DEPS_TEXT in error_context:
        error_context["error_message"] = (
            f"Missing dependencies: {', '.join(error_context['missing_deps'])}"
        )
        assert MISSING_TEXT in error_context["error_message"]
    else:
        # This is used by other scenarios, just ensure some error message exists
        if ERROR_MESSAGE_TEXT not in error_context or not error_context[ERROR_MESSAGE_TEXT]:
            error_context["error_message"] = "Error detected"
        assert error_context["error_message"] is not None


# Scenario: Validate and sanitize AI responses
@given("AI returns unexpected response format")
def unexpected_ai_response(error_context: dict[str, Any]) -> None:
    """Simulate unexpected AI response."""
    error_context["ai_responses"] = [
        '{"invalid": "json", "with": "errors",}',  # Trailing comma
        "Not JSON at all",  # Plain text
        '{"missing": "required_fields"}',  # Missing fields
    ]


@when("processing the response")
def process_response(error_context: dict[str, Any]) -> None:
    """Process AI response."""
    error_context["processing"] = True


@then("validation should catch format issues")
def validation_catches_issues(error_context: dict[str, Any]) -> None:
    """Verify validation catches format issues."""
    error_context["validation_errors"] = ["Invalid JSON", "Missing required field"]
    assert len(error_context["validation_errors"]) > 0


@then("response should be sanitized")
def response_sanitized(error_context: dict[str, Any]) -> None:
    """Verify response is sanitized."""
    error_context["sanitized_response"] = {"changes": [], "trivial": False}
    assert error_context["sanitized_response"] is not None


@then("default values should be used")
def default_values_used(error_context: dict[str, Any]) -> None:
    """Verify default values are used."""
    assert error_context["sanitized_response"]["trivial"] is False


@then("analysis should continue")
def analysis_continues_after_validation(error_context: dict[str, Any]) -> None:
    """Verify analysis continues."""
    error_context["continued"] = True
    assert error_context["continued"]


# Scenario: Handle repository access permissions
@given("limited read access to repository")
def limited_read_access(error_context: dict[str, Any]) -> None:
    """Simulate limited read access."""
    error_context["accessible_branches"] = ["main", "develop"]
    error_context["protected_branches"] = ["production", "staging"]


@when("analyzing protected branches")
def analyze_protected_branches(error_context: dict[str, Any]) -> None:
    """Attempt to analyze protected branches."""
    error_context["analyzing_protected"] = True


@then("permission errors should be handled")
def permission_errors_handled(error_context: dict[str, Any]) -> None:
    """Verify permission errors are handled."""
    error_context["permission_errors"] = ["Cannot access: production"]
    assert len(error_context["permission_errors"]) > 0


@then("accessible content should be analyzed")
def accessible_analyzed(error_context: dict[str, Any]) -> None:
    """Verify accessible content is analyzed."""
    error_context["analyzed_branches"] = ["main", "develop"]
    assert len(error_context["analyzed_branches"]) == ACCESSIBLE_ANALYZED_COUNT


@then("skipped content should be logged")
def skipped_content_logged(error_context: dict[str, Any]) -> None:
    """Verify skipped content is logged."""
    error_context["skipped_log"] = ["Skipped: production", "Skipped: staging"]
    assert len(error_context["skipped_log"]) > 0


@then("partial results should be generated")
def partial_results_generated(error_context: dict[str, Any]) -> None:
    """Verify partial results are generated."""
    error_context["partial_results_generated"] = True
    assert error_context["partial_results_generated"]


# Scenario: Graceful degradation for API failures
@given("Gemini API is partially available")
def api_partially_available(error_context: dict[str, Any]) -> None:
    """Simulate partial API availability."""
    error_context["api_success_rate"] = 0.7  # 70% success rate


@when("some requests fail")
def some_requests_fail(error_context: dict[str, Any]) -> None:
    """Simulate some request failures."""
    error_context["total_requests"] = 10
    error_context["failed_requests"] = 3
    error_context["successful_requests"] = 7


@then("successful requests should be preserved")
def successful_preserved(error_context: dict[str, Any]) -> None:
    """Verify successful requests are preserved."""
    assert error_context["successful_requests"] == SUCCESSFUL_PRESERVED_COUNT


@then("failed requests should be retried")
def failed_retried(error_context: dict[str, Any]) -> None:
    """Verify failed requests are retried."""
    error_context["retried_requests"] = 3
    assert error_context["retried_requests"] == error_context["failed_requests"]


@then("degraded mode should be indicated")
def degraded_mode_indicated(error_context: dict[str, Any]) -> None:
    """Verify degraded mode is indicated."""
    error_context["degraded_mode_message"] = "Operating in degraded mode (70% success rate)"
    assert DEGRADED_MODE_TEXT in error_context["degraded_mode_message"].lower()


@then("best-effort results should be generated")
def best_effort_results(error_context: dict[str, Any]) -> None:
    """Verify best-effort results are generated."""
    error_context["best_effort"] = True
    error_context["results_quality"] = "partial"
    assert error_context["best_effort"]
